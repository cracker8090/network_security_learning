[java架构学习导图](https://www.processon.com/view/link/5cb6c8a4e4b059e209fbf369#map) 

47.116.8.77

# mysql必知必会

## 数据库基本知识

### 什么是数据库

数据库是一个以某种有组织的方式存储数据集 合的软件。 数据库：保存有组织的数据的容器，通 常是一个文件或一组文件。    数据库软件应称为DBMS（数据库管理系统） 。在很大程度上说，数据库究竟是 文件还是别的什么东西并不重要，因为你并不直接访问数据 库；你使用的是DBMS，它替你访问数据库。    

### 表

在文件柜 中创建文件夹，然后将相关的资料放进特定的文件中。 在数据库领域中，这种文件夹称为 表。表是一种结构化的文件，可用来存储某种特定类型的数据。表可以保存顾客清单，产品 目录，或者其它信息清单。

	 表：某种特定类型数据的机构化清单。    

这里关键的一点在于，存储在表中的数据是一种类型的数据或一个清单。绝不应该将顾客的 清单与订单的清单存储在同一个数据库表中。这样做将使以后的检索和访问很困难。 数据库中的每个表都有一个名字，用来标识自己。此名字时唯 一的，这表示数据库中没有其它表具有相同的名字。    

	表名：表名的唯一性取决于多个因素，如数据库名和表名等的结合。虽然在同 一个数据库不能使用相同的表名，但在不同的数据库中却可以使用相同的表名    

表具有一些特性，这些特性定义了数据在表中如何存储，如可以**存储什么样的数据，数据如何分解，各部分信息如何命名**，等等。描述表的这组信息就是所谓的模式，模式可以用来描 述数据库中特定的表以及整个数据库（和其中表的关系） 。

	 模式：关于数据库和表的布局以及特性的信息    

### 列和数据类型 

表由列组成。列中存储着表中某部分的信息。    列：表中的一个字段。所有表都是由一个或多个列组成的。 理解列的最好办法是将表想象为 一个网格。网格中每一列存储着一条特定的信息。例如，在顾客表中，一个列存储着顾客编 号，另一个列存储着顾客名，而地址，城市，州以及邮政编号全都存储在各自的列中。 数据 库中每个列都有相应的数据类型。数据类型定义列可以存储的数据种类。    

	数据类型：所允许存储的数据的类型。每个列都有相应的数据数据类型，它限制该列中 存储的数据。    

数据类型限制可以存储在列中的数据种类。数据类型还帮助正确地排序数据，并在优化磁盘 使用方面起重要作用。因此，在创建表时必须对数据类型给予特别的关注。    

### 行

表中的数据是按行存储的，所保存的每个记录存储在自己的行内。如果将表想象为网格，网 格中垂直的列为表列，水平行为表行。 例如，顾客表可以每行存储一个顾客。表中的行数为 记录的总数。    

### 主键

表中每一行都应该有可以唯一标识自己的列。一个顾客表可以使用顾客编号列，而订单表可 以使用订单ID，雇员表可以使用雇员ID或雇员社会保险号。    唯一标识表中每行的这个列称为主键。主键用来表示一个特定的行。    表中的任何列都可以作为 主键，只要它满足以下条件：    

（1）任意两行都不具有相同的主键值    

（2）每个行都必须有一个主键值（不允许为null值）。主键通常定义的表的一列上，但这并不是必 须的，也可以一起使用多个列作为主键。在使用多列作为主键时，上述条件必须应用到 构成主键的所有列，所有列值的组合必须是唯一的（单个列的值可以不唯一） 。 还有一 种非常重要的键，称为外键，我们将在第15章中介绍。    

	主键：其值能够唯一标识表中每行数据    

第15章介绍外键。

SQL（Structured Query Language）是一种专门用来与数据库通信的语言。

SQL有如下的优点。

  SQL不是某个特定数据库供应商专有的语言。几乎所有重要的 DBMS都支持SQL，所以，学习此语言使你几乎能与所有数据库 打交道。

  SQL简单易学。它的语句全都是由描述性很强的英语单词组成， 而且这些单词的数目不多。

  SQL尽管看上去很简单，但它实际上是一种强有力的语言，灵活 使用其语言元素，可以进行非常复杂和高级的数据库操作。    

## 安装使用

事实上，多数网络的建立使用户不具有对数据的访问权，甚至不 具有对存储数据的驱动器的访问权。    

<http://dev.mysql.com/downloads/windows/installer/> 

安装路径可以修改一下 ，安装过程中的设置的密码很重要，要牢记。安装好之后，重要的一步是打开服务：控制面板 -> 管理工具 -> 服务，在里面找到MySQL56选项，右击->属性，在启动类型中选择 自动，然后点击启动，最后确定即可。 

 点击 MySQL 5.6 Command Line Client 启动命令行模式，输入密码： 

mysql工具

mysql命令行实用程序    

MySQL Administrator（MySQL管理器）

MySQL Query Browser



port：3306

root:1a2b3c4d5e6f:;!

windows service name:MySQL80



使用mysql



客户端

MySQL Workbench

Navicat for MySQL 

phpMyAdmin



# mysql安装使用

在CentOS中默认安装有MariaDB，这个是MySQL的分支，但为了需要，还是要在系统中安装MySQL，而且安装完成之后可以直接覆盖掉MariaDB。（mysql -u root -p 104104aa）

## 1 下载并安装MySQL官方的 Yum Repository

```
[root@localhost ~]# wget -i -c http://dev.mysql.com/get/mysql57-community-release-el7-10.noarch.rpm
```

  使用上面的命令就直接下载了安装用的Yum Repository，大概25KB的样子，然后就可以直接yum安装了。

```
[root@localhost ~]# yum -y install mysql57-community-release-el7-10.noarch.rpm
```

**注意：必须进入到 /etc/yum.repos.d/目录后再执行以下脚本** 

yum install mysql-server

systemctl start mysqld 

service mysqld start 

## 2.MariaDB 

此外,你也可以使用 MariaDB 代替，MariaDB 数据库管理系统是 MySQL 的一个分支，主要由开源社区在维护，采用 GPL 授权许可。开发这个分支的原因之一是：甲骨文公司收购了 MySQL 后，有将 MySQL 闭源的潜在风险，因此社区采用分支的方式来避开这个风险。

MariaDB的目的是完全兼容MySQL，包括API和命令行，使之能轻松成为MySQL的代替品。

```
yum install mariadb-server mariadb
```

```
systemctl start mariadb  #启动MariaDB
systemctl stop mariadb  #停止MariaDB
systemctl restart mariadb  #重启MariaDB
systemctl enable mariadb  #设置开机启动

vi /etc/my.cnf #添加 [mysqld] character_set_server=utf8 init_connect='SET NAMES utf8'

其他默认配置文件路径： 

配置文件：/etc/my.cnf 日志文件：/var/log//var/log/mysqld.log 服务启动脚本：/usr/lib/systemd/system/mysqld.service socket文件：/var/run/mysqld/mysqld.pid
select version();查看版本
```

```
mysqladmin --version
```

## 3.命令

你可以在 MySQL Client(Mysql客户端) 使用 mysql 命令连接到 MySQL 服务器上，默认情况下 MySQL 服务器的登录密码为空，所以本实例不需要输入密码。

命令如下：

```
[root@host]# mysql

SHOW DATABASES;列出 MySQL 数据库管理系统的数据库列表。
Mysql安装成功后，默认的root用户密码为空，你可以使用以下命令来创建root用户的密码：
mysqladmin -u root password "new_password";
可以通过以下命令来连接到Mysql服务器：
mysql -u root -p
mysql -u ben -p -h myserver -P 9999
```

```
ps -ef | grep mysqld
启动mysql服务器
oot@host# cd /usr/bin
./mysqld_safe &
关闭mysql服务器
root@host# cd /usr/bin
./mysqladmin -u root -p shutdown
以下为添加用户的的实例，用户名为guest，密码为guest123，并授权用户可进行 SELECT, INSERT 和 UPDATE操作权限：
SHOW TABLES:列表
显示指定数据库的所有表，使用该命令前需要使用 use 命令来选择要操作的数据库
SHOW COLUMNS FROM 数据表:
显示数据表的属性，属性类型，主键信息 ，是否为 NULL，默认值等其他信息。
SHOW INDEX FROM 数据表:
显示数据表的详细索引信息，包括PRIMARY KEY（主键）。

SHOW TABLE STATUS LIKE [FROM db_name] [LIKE 'pattern'] \G: 
该命令将输出Mysql数据库管理系统的性能及统计信息。

mysql> SHOW TABLE STATUS  FROM RUNOOB;   # 显示数据库 RUNOOB 中所有表的信息
mysql> SHOW TABLE STATUS from RUNOOB LIKE 'runoob%';     # 表名以runoob开头的表的信息
mysql> SHOW TABLE STATUS from RUNOOB LIKE 'runoob%'\G;   # 加上 \G，查询结果按列打印

mysql> show engines;查看MySQL提供的所有存储引擎

SHOW STATUS，用于显示广泛的服务器状态信息；
SHOW CREATE DATABASE和SHOW CREATE TABLE，分别用来显示创建特定数据库或表的MySQL语句；
SHOW GRANTS，用来显示授予用户（所有用户或特定用户）的安全权限；
SHOW ERRORS和SHOW WARNINGS， 用来显示服务器错误或警告消息



```

## MyISAM和InnoDB区别

MyISAM是MySQL的默认数据库引擎（5.5版之前）。虽然性能极佳，而且提供了大量的特性，包括全文索引、压缩、空间函数等，但MyISAM不支持事务和行级锁，而且最大的缺陷就是崩溃后无法安全恢复。不过，5.5版本之后，MySQL引入了InnoDB（事务性数据库引擎），MySQL 5.5版本后默认的存储引擎为InnoDB。

大多数时候我们使用的都是 InnoDB 存储引擎，但是在某些情况下使用 MyISAM 也是合适的比如读密集的情况下。（如果你不介意 MyISAM 崩溃恢复问题的话）。

**两者的对比：**

1. **是否支持行级锁** : MyISAM 只有表级锁(table-level locking)，而InnoDB 支持行级锁(row-level locking)和表级锁,默认为行级锁。
2. **是否支持事务和崩溃后的安全恢复： MyISAM** 强调的是性能，每次查询具有原子性,其执行速度比InnoDB类型更快，但是不提供事务支持。但是**InnoDB** 提供事务支持事务，外部键等高级数据库功能。 具有事务(commit)、回滚(rollback)和崩溃修复能力(crash recovery capabilities)的事务安全(transaction-safe (ACID compliant))型表。
3. **是否支持外键：** MyISAM不支持，而InnoDB支持。
4. **是否支持MVCC** ：仅 InnoDB 支持。应对高并发事务, MVCC比单纯的加锁更高效;MVCC只在 `READ COMMITTED` 和 `REPEATABLE READ` 两个隔离级别下工作;MVCC可以使用 乐观(optimistic)锁 和 悲观(pessimistic)锁来实现;各数据库中MVCC实现并不统一。推荐阅读：[MySQL-InnoDB-MVCC多版本并发控制](https://segmentfault.com/a/1190000012650596)
5. ......

《MySQL高性能》上面有一句话这样写到:

> 不要轻易相信“MyISAM比InnoDB快”之类的经验之谈，这个结论往往不是绝对的。在很多我们已知场景中，InnoDB的速度都可以让MyISAM望尘莫及，尤其是用到了聚簇索引，或者需要访问的数据都可以放入内存的应用。

一般情况下我们选择 InnoDB 都是没有问题的，但是某些情况下你并不在乎可扩展能力和并发能力，也不需要事务支持，也不在乎崩溃后的安全恢复问题的话，选择MyISAM也是一个不错的选择。但是一般情况下，我们都是需要考虑到这些问题的。 



# MySQL 基本架构

下图是 MySQL  的一个简要架构图，从下图你可以很清晰的看到用户的 SQL 语句在 MySQL 内部是如何执行的。

先简单介绍一下下图涉及的一些组件的基本作用帮助大家理解这幅图，在后面会详细介绍到这些组件的作用。

- **连接器：** 身份认证和权限相关(登录 MySQL 的时候)。
- **查询缓存:**  执行查询语句的时候，会先查询缓存（MySQL 8.0 版本后移除，因为这个功能不太实用）。
- **分析器:**  没有命中缓存的话，SQL 语句就会经过分析器，分析器说白了就是要先看你的 SQL 语句要干嘛，再检查你的 SQL 语句语法是否正确。
- **优化器：**  按照 MySQL 认为最优的方案去执行。
- **执行器:** 执行语句，然后从存储引擎返回数据。

![](https://user-gold-cdn.xitu.io/2019/3/23/169a8bc60a083849?w=950&h=1062&f=jpeg&s=38189)

简单来说 MySQL  主要分为 Server 层和存储引擎层：

- **Server 层**：主要包括连接器、查询缓存、分析器、优化器、执行器等，所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图，函数等，还有一个通用的日志模块 binglog 日志模块。
- **存储引擎**： 主要负责数据的存储和读取，采用可以替换的插件式架构，支持 InnoDB、MyISAM、Memory 等多个存储引擎，其中 InnoDB 引擎有自有的日志模块 redolog 模块。**现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始就被当做默认存储引擎了。**

## Server 层基本组件介绍

### 1) 连接器

连接器主要和身份认证和权限相关的功能相关，就好比一个级别很高的门卫一样。

主要负责用户登录数据库，进行用户的身份认证，包括校验账户密码，权限等操作，如果用户账户密码已通过，连接器会到权限表中查询该用户的所有权限，之后在这个连接里的权限逻辑判断都是会依赖此时读取到的权限数据，也就是说，后续只要这个连接不断开，即时管理员修改了该用户的权限，该用户也是不受影响的。

### 2) 查询缓存(MySQL 8.0 版本后移除)

查询缓存主要用来缓存我们所执行的 SELECT 语句以及该语句的结果集。

连接建立后，执行查询语句的时候，会先查询缓存，MySQL 会先校验这个 sql 是否执行过，以 Key-Value 的形式缓存在内存中，Key 是查询预计，Value 是结果集。如果缓存 key 被命中，就会直接返回给客户端，如果没有命中，就会执行后续的操作，完成后也会把结果缓存起来，方便下一次调用。当然在真正执行缓存查询的时候还是会校验用户的权限，是否有该表的查询条件。

MySQL 查询不建议使用缓存，因为查询缓存失效在实际业务场景中可能会非常频繁，假如你对一个表更新的话，这个表上的所有的查询缓存都会被清空。对于不经常更新的数据来说，使用缓存还是可以的。

所以，一般在大多数情况下我们都是不推荐去使用查询缓存的。

MySQL 8.0 版本后删除了缓存的功能，官方也是认为该功能在实际的应用场景比较少，所以干脆直接删掉了。

### 3) 分析器

MySQL 没有命中缓存，那么就会进入分析器，分析器主要是用来分析 SQL 语句是来干嘛的，分析器也会分为几步：

**第一步，词法分析**，一条 SQL 语句有多个字符串组成，首先要提取关键字，比如 select，提出查询的表，提出字段名，提出查询条件等等。做完这些操作后，就会进入第二步。

**第二步，语法分析**，主要就是判断你输入的 sql 是否正确，是否符合 MySQL 的语法。

完成这 2 步之后，MySQL 就准备开始执行了，但是如何执行，怎么执行是最好的结果呢？这个时候就需要优化器上场了。

### 4) 优化器 

优化器的作用就是它认为的最优的执行方案去执行（有时候可能也不是最优，这篇文章涉及对这部分知识的深入讲解），比如多个索引的时候该如何选择索引，多表查询的时候如何选择关联顺序等。

可以说，经过了优化器之后可以说这个语句具体该如何执行就已经定下来。

### 5) 执行器

当选择了执行方案后，MySQL 就准备开始执行了，首先执行前会校验该用户有没有权限，如果没有权限，就会返回错误信息，如果有权限，就会去调用引擎的接口，返回接口执行的结果。





## MySQL发展历史

应用程序都可以按照统一的方式直接操作数据，也就是应用程序和数据都具有了高度的独立性。

![img](https://images2015.cnblogs.com/blog/63651/201703/63651-20170308091123641-636480917.jpg)



## 常见数据库技术品牌、服务与架构

发展了这么多年市场上出现了许多的数据库系统，最强的个人认为是Oracle，当然还有许多如：DB2、Microsoft SQL Server、MySQL、SyBase等，下图列出常见数据库技术品牌、服务与架构。

![img](https://images2015.cnblogs.com/blog/63651/201703/63651-20170308091629219-1179178843.jpg)



## MySQL引擎比较

MySQL 的存储引擎接口定义良好。有兴趣的开发者可以通过阅读文档编写自己的存储引擎。

![img](https://images2015.cnblogs.com/blog/63651/201703/63651-20170308122741453-767743951.png)

## MySQL操作实例

[一个小时学会MySQL数据库](https://www.cnblogs.com/best/p/6517755.html) 



# [ehcache、memcache、redis比较](https://www.cnblogs.com/qlqwjy/p/7788912.html)  

## **Ehcache** 

在[Java](http://lib.csdn.net/base/javase)项目广泛的使用。它是一个开源的、设计于提高在数据从RDBMS中取出来的高花费、高延迟采取的一种缓存方案。正因为Ehcache具有健壮性（基于java开发）、被认证（具有apache 2.0  license）、充满特色（稍后会详细介绍），所以被用于大型复杂分布式web application的各个节点中。 

### 1.够快

Ehcache的发行有一段时长了，经过几年的努力和不计其数的性能[测试](http://lib.csdn.net/base/softwaretest)，Ehcache终被设计于large, high concurrency systems.

### 2.够简单

开发者提供的接口非常简单明了，从Ehcache的搭建到运用运行仅仅需要的是你宝贵的几分钟。其实很多开发者都不知道自己用在用Ehcache，Ehcache被广泛的运用于其他的开源项目

比如：[hibernate](http://lib.csdn.net/base/javaee)

### 3.够袖珍

关于这点的特性，官方给了一个很可爱的名字small foot print ，一般Ehcache的发布版本不会到2M，V 2.2.3  才 668KB。

### 4.够轻量

核心程序仅仅依赖slf4j这一个包，没有之一！

### 5.好扩展

Ehcache提供了对[大数据](http://lib.csdn.net/base/hadoop)的内存和硬盘的存储，最近版本允许多实例、保存对象高灵活性、提供LRU、LFU、FIFO淘汰[算法](http://lib.csdn.net/base/datastructure)，基础属性支持热配置、支持的插件多

### 6.监听器

缓存管理器监听器 （CacheManagerListener）和 缓存监听器（CacheEvenListener）,做一些统计或数据一致性广播挺好用的



```
CacheManager manager = CacheManager.newInstance("src/config/ehcache.xml");
Ehcache cache = new Cache("testCache", 5000, false, false, 5, 2);
cacheManager.addCache(cache);
```

## **memcache** 

memcache 是一种高性能、分布式对象缓存系统，最初设计于缓解动态网站[数据库](http://lib.csdn.net/base/mysql)加载数据的延迟性，你可以把它想象成一个大的内存HashTable，就是一个key-value键值缓存。Danga Interactive为了LiveJournal所发展的，以BSD license释放的一套开放源代码软件。

### 1.依赖

memcache [C语言](http://lib.csdn.net/base/c)所编写，依赖于最近版本的GCC和libevent。GCC是它的编译器，同事基于libevent做socket io。在安装memcache时保证你的系统同事具备有这两个环境。

### 2.多线程支持

memcache支持多个cpu同时工作，在memcache安装文件下有个叫threads.txt中特别说明，By default, memcached is compiled as a single-threaded application.默认是单线程编译安装，如果你需要多线程则需要修改./configure --enable-threads，为了支持多核系统，前提是你的系统必须具有多线程工作模式。开启多线程工作的线程数默认是4，如果线程数超过cpu数 容易发生操作死锁的概率。结合自己业务模式选择才能做到物尽其用。

### 3.高性能

通过libevent完成socket 的通讯，理论上性能的瓶颈落在网卡上。

### 4.简单安装

```
1.分别把memcached和libevent下载回来，放到 /tmp 目录下：

\# cd /tmp

\# wget http://www.danga.com/memcached/dist/memcached-1.2.0.tar.gz

\# wget http://www.monkey.org/~provos/libevent-1.2.tar.gz

![img](http://img.my.csdn.net/uploads/201301/17/1358386757_5640.jpg)

2.先安装libevent：

\# tar zxvf libevent-1.2.tar.gz

\# cd libevent-1.2

\# ./configure -prefix=/usr

\# make （如果遇到提示gcc 没有安装则先安装gcc)

\# make install

3.测试libevent是否安装成功：

\# ls -al /usr/lib | grep libevent

lrwxrwxrwx 1 root root 21 11?? 12 17:38 libevent-1.2.so.1 -> libevent-1.2.so.1.0.3

-rwxr-xr-x 1 root root 263546 11?? 12 17:38 libevent-1.2.so.1.0.3

-rw-r-r- 1 root root 454156 11?? 12 17:38 libevent.a

-rwxr-xr-x 1 root root 811 11?? 12 17:38 libevent.la

lrwxrwxrwx 1 root root 21 11?? 12 17:38 libevent.so -> libevent-1.2.so.1.0.3

还不错，都安装上了。

4.安装memcached，同时需要安装中指定libevent的安装位置：

\# cd /tmp

\# tar zxvf memcached-1.2.0.tar.gz

\# cd memcached-1.2.0

\# ./configure -with-libevent=/usr

\# make

\# make install

如果中间出现报错，请仔细检查错误信息，按照错误信息来配置或者增加相应的库或者路径。

安装完成后会把memcached放到 /usr/local/bin/memcached ，

5.测试是否成功安装memcached：

\# ls -al /usr/local/bin/mem*

-rwxr-xr-x 1 root root 137986 11?? 12 17:39 /usr/local/bin/memcached

-rwxr-xr-x 1 root root 140179 11?? 12 17:39 /usr/local/bin/memcached-debug
```



### 5.启动Memcache的服务器端：

```
\# /usr/local/bin/memcached -d -m 8096 -u root -l 192.168.77.105 -p 12000 -c 256 -P /tmp/memcached.pid

-d选项是启动一个守护进程，

-m是分配给Memcache使用的内存数量，单位是MB，我这里是8096MB，

-u是运行Memcache的用户，我这里是root，

-l是监听的服务器IP地址，如果有多个地址的话，我这里指定了服务器的IP地址192.168.77.105，

-p是设置Memcache监听的端口，我这里设置了12000，最好是1024以上的端口，

-c选项是最大运行的并发连接数，默认是1024，我这里设置了256，按照你服务器的负载量来设定，

-P是设置保存Memcache的pid文件，我这里是保存在 /tmp/memcached.pid，


2.如果要结束Memcache进程，执行：

\# cat /tmp/memcached.pid 或者 ps -aux | grep memcache   （找到对应的进程id号）

\# kill 进程id号

也可以启动多个守护进程，不过端口不能重复。

 memcache 的连接

telnet  ip   port 

注意连接之前需要再memcache服务端把memcache的防火墙规则加上

-A RH-Firewall-1-INPUT -m state --state NEW -m tcp -p tcp --dport 3306 -j ACCEPT 

重新加载防火墙规则

service iptables restart

OK ,现在应该就可以连上memcache了

在客户端输入stats 查看memcache的状态信息

![img](http://img.my.csdn.net/uploads/201301/17/1358386780_1884.jpg)



pid              memcache服务器的进程ID

uptime      服务器已经运行的秒数

time           服务器当前的unix时间戳

version     memcache版本

pointer_size         当前[操作系统](http://lib.csdn.net/base/operatingsystem)的指针大小（32位系统一般是32bit）

rusage_user          进程的累计用户时间

rusage_system    进程的累计系统时间

curr_items            服务器当前存储的items数量

total_items           从服务器启动以后存储的items总数量

bytes                       当前服务器存储items占用的字节数

curr_connections        当前打开着的连接数

total_connections        从服务器启动以后曾经打开过的连接数

connection_structures          服务器分配的连接构造数

cmd_get get命令          （获取）总请求次数

cmd_set set命令          （保存）总请求次数

get_hits          总命中次数

get_misses        总未命中次数

evictions     为获取空闲内存而删除的items数（分配给memcache的空间用满后需要删除旧的items来得到空间分配给新的items）

bytes_read    读取字节数（请求字节数）

bytes_written     总发送字节数（结果字节数）

limit_maxbytes     分配给memcache的内存大小（字节）

threads         当前线程数
```

## redis

 [Redis](http://lib.csdn.net/base/redis)是 在memcache之后编写的，大家经常把这两者做比较，如果说它是个key-value store 的话但是它具有丰富的数据类型，我想暂时把它叫做缓存数据流中心，就像现在物流中心那样，order、package、store、 classification、distribute、end。现在还很流行的LAMP [PHP](http://lib.csdn.net/base/php)[架构](http://lib.csdn.net/base/architecture) 不知道和 redis+[MySQL](http://lib.csdn.net/base/mysql) 或者 redis + [MongoDB](http://lib.csdn.net/base/mongodb)的性能比较（听群里的人说mongodb分片不稳定）。













### 1.支持持久化

     redis的本地持久化支持两种方式：RDB和AOF。RDB 在redis.conf配置文件里配置持久化触发器，AOF指的是redis没增加一条记录都会保存到持久化文件中（保存的是这条记录的生成命令），如果 不是用redis做DB用的话还会不要开AOF ，数据太庞大了，重启恢复的时候是一个巨大的工程！

### 2.丰富的数据类型

    redis 支持 String 、Lists、sets、sorted sets、hashes 多种数据类型,新浪微博会使用redis做nosql主要也是它具有这些类型，时间排序、职能排序、我的微博、发给我的这些功能List 和 sorted set的强大操作功能息息相关

### 3.高性能

   这点跟memcache很想象，内存操作的级别是毫秒级的比硬盘操作秒级操作自然高效不少，较少了磁头寻道、数据读取、页面交换这些高开销的操作！这也是NOSQL冒出来的原因吧，应该是高性能

  是基于RDBMS的衍生产品，虽然RDBMS也具有缓存结构，但是始终在app层面不是我们想要的那么操控的。

### 4.replication

    redis提供主从复制方案，跟mysql一样增量复制而且复制的实现都很相似，这个复制跟AOF有点类似复制的是新增记录命令，主库新增记录将新增脚本 发送给从库，从库根据脚本生成记录，这个过程非常快，就看网络了，一般主从都是在同一个局域网，所以可以说redis的主从近似及时同步，同事它还支持一 主多从，动态添加从库，从库数量没有限制。 主从库搭建，我觉得还是采用网状模式，如果使用链式（master-slave-slave-slave-slave·····）如果第一个slave出 现宕机重启，首先从master 接收 数据恢复脚本，这个是阻塞的，如果主库数据几TB的情况恢复过程得花上一段时间，在这个过程中其他的slave就无法和主库同步了。

### 5.更新快

   这点好像从我接触到redis到目前为止 已经发了大版本就4个，小版本没算过。redis作者是个非常积极的人，无论是邮件提问还是论坛发帖，他都能及时耐心的为你解答，维护度很高。有人维护的 话，让我们用的也省心和放心。目前作者对redis 的主导开发方向是redis的集群方向。

### 6.改进

为什么redis不支持多线程多核心处理呢？作者也发表了一下自己的看法，首先是多线程不变于bug的修复，其实是不 易软件的扩展，还有数据一致性问题因为redis所有的操作都是原子操作，作者用到一个词nightmare 噩梦，呵呵！  当然不支持多线程操作，肯定也有他的弊端的比如性能想必必然差，作者从2.2版本后专注redis cluster的方向开发来缓解其性能上的弊端，说白了就是纵向不行，横向提高。

## 应用场景

```
ehcache直接在jvm虚拟机中缓存，速度快，效率高；但是缓存共享麻烦，集群分布式应用不方便。

redis是通过socket访问到缓存服务，效率比ecache低，比数据库要快很多，处理集群和分布式缓存方便，有成熟的方案。

如果是单个应用或者对缓存访问要求很高的应用，用ehcache。

如果是大型系统，存在缓存共享、分布式部署、缓存内容很大的，建议用redis。

补充下：ehcache也有缓存共享方案，不过是通过RMI或者Jgroup多播方式进行广播缓存通知更新，缓存共享复杂，维护不方便；简单的共享可以，但是涉及到缓存恢复，大数据缓存，则不合适

redis和memcached相比的独特之处：
1、redis可以用来做存储(storage),而memcached是用来做缓存(cache)
这个特点主要因为其有持久化功能

2、redis中存储的数据有多种结构，而memcached存储的数据只有一种类型“字符串”
```

## 实际代码操作

```
第二种理解:
第一：两者之间的介绍

Redis：属于独立的运行程序，需要单独安装后，使用JAVA中的Jedis来操纵。因为它是独立，所以如果你写个单元测试程序，放一些数据在Redis中，然后又写一个程序去拿数据，那么是可以拿到这个数据的。，

ehcache：与Redis明显不同，它与java程序是绑在一起的，java程序活着，它就活着。譬如，写一个独立程序放数据，再写一个独立程序拿数据，那么是拿不到数据的。只能在独立程序中才能拿到数据。

第二：使用及各种配置：

两者都可以集群：

1.Redis可以做主从来集群，例如，在A电脑上装个Redis，作为主库；在其他电脑上装Redis，作为从库；这样主库拥有读和写的功能，而从库只拥有读的功能。每次主库的数据都会同步到从库中。

1.默认方式启动

Linux下使用Redis 
安装：从官网上下载tar.gz格式的包，然后使用tar zxvf redis-2.8.24.tar.gz命令解压，然后进入Redis文件夹目录下的src目录，使用make编译一下 
   
1.开启：进入/usr/local/redis-3.2.1/src 
然后./redis-server 

2.如果我们想修改端口，设置密码：那么得修改配置文件的redis.conf
port 6379                                         //端口修改
requirepass redis123                  //设置密码  redis123为密码

配置主从：主库的配置文件不用修改，从库的配置文件需要修改，因为从库需要绑定主库，以便可以获取主库的数据

slaveof 192.168.1.100 6379                              //主库的IP地址和端口号
masterauth redis123                                      //主库设定的密码

3.要让配置文件的属性生效，那么启动的redis的时候，要将配置文件加上去

进入/usr/local/redis-3.2.1/src
然后 ./redis-server  redis.conf

那么将成功的启动redis，如果没有加入配置的话，按照普通方式启动的话，端口仍然还是6379.

4.客户端连接远程的Redis
第一步：在远程端处设置密码：config set requirepass 123       //123为密码
第二步：可以在客户端登录  redis-cli.exe -h 114.215.125.42 -p 6379 
第三步：认证：auth 123                                       //123为密码
本地端设置密码后，要使用密码登录；如果Redis重启的话，密码需要重新设置

5.主从配置后，为保证主库写的能力，一般不在主库做持久化，而是在从库做持久化：

主库配置：
将save注释，不使用rdb
# save 900 1
# save 300 10
# save 60 10000

appendonly no        不使用aof

从库配置：
save 900 1
save 300 10
save 60 10000

appendonly yes

这样做的优缺点：
优点：保证了主库写的能力。

缺点：主库挂掉后，重启主库，然后进行第一次写的动作后，主库会先生成rdb文件，然后传输给从库，从而覆盖掉从库原先的rdb文件，造成数据丢失。但是第二次写的时候，主库会以快照方式直接传数据给从库，不会重新生成rdb文件。

解决方案：先复制从库中的数据到主库后，再启动主库。

使用：
引入jedis包
    <dependency>  
        <groupId>redis.clients</groupId>  
        <artifactId>jedis</artifactId>  
        <version>2.7.3</version>  
    </dependency>  
简单的写个类玩玩吧
    public class RedisMain {  
        public static void main(String [] str)  
        {  
              
             Jedis jedis = new Jedis("114.215.125.42",6379);  
             jedis.auth("123");     //密码认证  
              System.out.println("Connection to server sucessfully");  
              //查看服务是否运行  
              jedis.set("user","namess");  
             // System.out.println("Server is running: "+jedis.ping());  
              System.out.println(jedis.get("user").toString());  
              jedis.set("user","name");  
              System.out.println(jedis.get("user"));  
        }  
    }  
Redis完毕

下面说说Ehcache:

Ehcache的使用：
1.首先引入包
    <dependency>  
               <groupId>net.sf.ehcache</groupId>  
               <artifactId>ehcache-core</artifactId>  
               <version>2.6.6</version>  
           </dependency>  
       
           <dependency>  
               <groupId>org.slf4j</groupId>  
               <artifactId>slf4j-log4j12</artifactId>  
               <version>1.6.6</version>  
           </dependency>  

2.创建一个ehcache.xml文件，里面配置cache的信息，这个配置是包含了集群的配置：与192.168.93.129：40001的 机器集群了：Ip为192.168.93.129机子的配置要将rmiUrls对应的数据改为这个配置文件的机子的IP地址，和对应的缓存名字

    <ehcache xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"  
       xsi:noNamespaceSchemaLocation="ehcache.xsd">  
        <cacheManagerPeerProviderFactory   
       class="net.sf.ehcache.distribution.RMICacheManagerPeerProviderFactory"  
    properties="peerDiscovery=manual,rmiUrls=//192.168.93.129:40001/demoCache"/>           <!--另一台机子的ip缓存信息-->  
    <cacheManagerPeerListenerFactory class="net.sf.ehcache.distribution.RMICacheManagerPeerListenerFactory"  
    properties="hostName=localhost,port=40001,socketTimeoutMillis=2000" />                  <!--hostName代表本机子的ip-->     
      <diskStore path="java.io.tmpdir"/>  
      <defaultCache  
        maxElementsInMemory="10000"  
        maxElementsOnDisk="0"  
        eternal="true"  
        overflowToDisk="true"  
        diskPersistent="false"  
        timeToIdleSeconds="0"  
        timeToLiveSeconds="0"  
        diskSpoolBufferSizeMB="50"  
        diskExpiryThreadIntervalSeconds="120"  
        memoryStoreEvictionPolicy="LFU"  
        >  
         <cacheEventListenerFactory    
                    class="net.sf.ehcache.distribution.RMICacheReplicatorFactory"/>                
        </defaultCache>  
      <cache name="demoCache"  
        maxElementsInMemory="100"  
        maxElementsOnDisk="0"  
        eternal="false"  
        overflowToDisk="false"  
        diskPersistent="false"  
        timeToIdleSeconds="119"  
        timeToLiveSeconds="119"  
        diskSpoolBufferSizeMB="50"  
        diskExpiryThreadIntervalSeconds="120"  
        memoryStoreEvictionPolicy="FIFO"  
        >  
        <cacheEventListenerFactory class="net.sf.ehcache.distribution.RMICacheReplicatorFactory"/>          <!--监听这个cache-->  
        </cache>  
    </ehcache>  

配置完后写代码：

放数据：
    @RequestMapping("/testehcache.do")  
        public void testehcache(HttpServletResponse response) throws IOException  
        {  
            URL url = getClass().getResource("ehcache.xml");   
             CacheManager singletonmanager = CacheManager.create(url);  
            Cache cache = singletonmanager.getCache("demoCache");  
            //使用缓存  
            Element element = new Element("key1", "value1");  
            cache.put(element);  
            cache.put(new Element("key2", "value2"));  
             
            response.getWriter().println("我存放了数据");  
        }  

拿数据：
@RequestMapping("/getcache.do")  
    public void getcache(HttpServletResponse response) throws IOException  
    {  
        CacheManager singletonmanager = CacheManager.create();   
        Cache cache = singletonmanager.getCache("demoCache");  
        String one=cache.get("key1").getObjectValue().toString();  
        String two=cache.get("key2").getObjectValue().toString();  
        response.getWriter().println(one+two);  
    } 
配置集群后，A机器放数据，在B机器上能拿到数据，B机器放数据，A机器也可以拿到数据
```



# Redis学习

## 1.书籍推荐

[redis实战](https://book.douban.com/subject/26612779/)  《Redis实战》是《Redis in Action》

在线阅读地址：<http://redisinaction.com/index.html>

redis设计与实现  [带有详细注释的 Redis 2.6 源码](https://github.com/huangz1990/annotated_redis_source/) 

在线阅读地址：<http://redisbook.readthedocs.io/en/latest/index.html>

[redis在线学习网站](http://try.redis.io/) 

[the-little-redis-book](https://github.com/JasonLai256/the-little-redis-book/blob/master/cn/redis.md)  

[redis命令参考](http://doc.redisfans.com/) 

<https://redis.readthedocs.io/en/latest/> 

## 2.[非关系型数据库可以学习的课程](https://www.jianshu.com/p/b768b7adae12) 

**课程：面向文档数据库——【[mongoDB基础教程](https://www.shiyanlou.com/courses/12)】**

Mongo最大的特点是他支持的查询语言非常强大，其语法有点类似于面向对象的查询语言，几乎可以实现类似关系数据库单表查询的绝大部分功能，而且还支持对数据建立索引。

通过课程了解monggoDB的基本操作、数据查询、文档操作、以及一些高级语法；

课程：键值存储数据库——【[Redis基础教](https://www.shiyanlou.com/courses/106)程】

Redis 是一个高性能的key-value数据库。Redis支持主从同步，可执行单层树复制。

课程介绍Redis系统的基本配置和使用方法。

课程：列存储数据库——【[HBASE基础教程](https://www.shiyanlou.com/courses/37)】

HBASE是Hadoop项目的一部分，运行于HDFS文件系统之上，为 Hadoop 提供类似于BigTable 规模的服务。

通过课程了解HBASE的基础配置以及使用方法。

## 3.Redis实战

该书深入浅出地介绍了 Redis 的字符串、列表、散列、集合、有序集合等五种结构， 并通过文章聚合网站、cookie、购物车、网页缓存、日志、计数器、IP 所属地址查询程序、自动补全、分布式锁、计数信号量、任务队列、消息队列、搜索程序、广告定向程序、社交网站等一系列实用示例展示了 Redis 的用法。

除此之外， 《Redis实战》还介绍了使用短结构、分片、事务、流水线、复制、Lua 脚本等手段来扩展和优化 Redis 的方法， 这些技术可以大幅地扩展系统的性能， 并尽可能地降低程序所需的内存数量。

综上所述， 《Redis实战》将是一本对于学习和使用 Redis 来说不可多得的参考书籍， 无论是 Redis 新手还是有一定经验的 Redis 使用者， 应该都能从本书中获益。







### redis配置

　　daemonize：如需要在后台运行，把该项的值改为yes

　　pdifile：把pid文件放在/var/run/redis.pid，可以配置到其他地址

　　bind：指定redis只接收来自该IP的请求，如果不设置，那么将处理所有请求，在生产环节中最好设置该项

　　port：监听端口，默认为6379

　　timeout：设置客户端连接时的超时时间，单位为秒

　　loglevel：等级分为4级，debug，revbose，notice和warning。生产环境下一般开启notice

　　logfile：配置log文件地址，默认使用标准输出，即打印在命令行终端的端口上

　　database：设置数据库的个数，默认使用的数据库是0

　　save：设置redis进行数据库镜像的频率

　　rdbcompression：在进行镜像备份时，是否进行压缩

　　dbfilename：镜像备份文件的文件名

　　dir：数据库镜像备份的文件放置的路径

　　slaveof：设置该数据库为其他数据库的从数据库

　　masterauth：当主数据库连接需要密码验证时，在这里设定

　　requirepass：设置客户端连接后进行任何其他指定前需要使用的密码

　　maxclients：限制同时连接的客户端数量

　　maxmemory：设置redis能够使用的最大内存

　　appendonly：开启appendonly模式后，redis会把每一次所接收到的写操作都追加到appendonly.aof文件中，当redis重新启动时，会从该文件恢复出之前的状态

　　appendfsync：设置appendonly.aof文件进行同步的频率

　　vm_enabled：是否开启虚拟内存支持

　　vm_swap_file：设置虚拟内存的交换文件的路径

　　vm_max_momery：设置开启虚拟内存后，redis将使用的最大物理内存的大小，默认为0

　　vm_page_size：设置虚拟内存页的大小

　　vm_pages：设置交换文件的总的page数量

　　vm_max_thrrads：设置vm IO同时使用的线程数量







## 4.Netty、Redis、Zookeeper高并发实战pdf







## 5.redis and docker

### 1.阿里云docker部署redis

```
docker search redis
docker pull redis
docker images

docker run -p 6379:6379 -v $PWD/data:/data --name redis_1 -d redis redis-server --appendonly yes
docker run -p 6379:6379 -v /docker/redis/redis.conf:/etc/redis/redis.conf -v /docker/redis/data:/data --name redis1 -d redis redis-server --appendonly yes

    docker run -p 6379:6379 -v /docker/redis/redis.conf:/etc/redis/redis.conf -v /docker/redis/data:/data --name myredis -d redis redis-server --appendonly yes


//-p  指定端口  
//-v  指定目录下的data目录挂载
//-name 指定容器名称
//-d 指定镜像名称后台运行
//redis-server --appendonly yes  在容器执行redis-server启动命令，并打开redis持久化配置


下载和编译
$ wget http://download.redis.io/releases/redis-5.0.7.tar.gz
$ tar xzf redis-5.0.7.tar.gz
$ cd redis-5.0.7
$ make

阿里云docker配置：
redis.conf文件中有个daemonize yes的初始默认值，默认redis以后台形式运行会和docker的启动选项冲突，必须注释掉或者改为no
redis.conf的bind 127.0.0.1注释掉
requirepass 123456
docker run -d -p 6379:6379 -v /docker/redis/redis.conf:/etc/redis/redis.conf -v /docker/redis/data:/data --name redis_1 redis redis-server /etc/redis/redis.conf
-p：指定端口映射，前面的代表容器的pid，后面的代表服务器的pid
-v：配置文件和持久化存储的挂载，前面的是服务器的文件路径，后面的是容器的路径。
最后指定使用容器中的/etc/redis/redis.conf配置文件启动redis。

#bind 127.0.0.1 //允许远程连接
protected-mode no
appendonly yes //持久化
requirepass 123456 //密码 

netstat -lntp | grep 6379

config set requirepass "yourpassword" // 设置当前密码，服务重新启动后又会置为默认，即无密码；
config get requirepass // 获取当前密码
添加requirepass yourpassword（此处注意，行前不能有空格），保存之后，重启Redis服务。

config set requirepass 123456
config get requirepass
service redis restart

master配置了密码，slave如何配置
若master配置了密码则slave也要配置相应的密码参数否则无法进行正常复制的。
slave中配置文件内找到如下行，移除注释，修改密码即可
#masterauth  mstpassword
```

### 2.阿里云部署redis集群

[使用Docker Compose部署基于Sentinel的高可用Redis集群](https://yq.aliyun.com/articles/57953?spm=a2c6h.13066369.0.0.ab14346bYQ0Fkr&do=login) 

<https://www.imooc.com/article/277939> 容器配置内网ip 桥接



### 3.docker部署redis与其他容器

使用Docker的时候，经常可能需要连接到其他的容器，比如：web服务需要连接数据库。按照往常的做法，需要先启动数据库的容器，映射出端口来，然后配置好客户端的容器，再去访问。其实针对这种场景，Docker提供了--link 参数来满足。
--link=container_name or id:name

```
$ docker run --name some-app --link some-redis:redis -d application-that-uses-redis
或者
$ docker run -it --link some-redis:redis --rm redis redis-cli -h redis -p 6379

docker run --name=mysql_server -d -P kongxx/mysql_server
docker run --name=mysql_client1 --link=mysql_server:db -t -i kongxx/mysql_client /usr/bin/mysql -h db -u root -pletmein
“–link=mysql_server:db”，这个参数就是告诉Docker容器需要使用“mysql_server”容器，并将其别名命名为db，这样在这两个容器里就可以使用“db”来作为提供mysql数据库服务的机器名。所以在最后启动参数里我们使用的是“/usr/bin/mysql -h db -u root -pletmein”来连接mysql数据库的。
jdbc:mysql://db:3306/test?useUnicode=true&characterEncoding=utf8&useSSL=false

```



*systemctl statusfirewalld*

*systemctl stop firewalld* 

docker network ls

默认情况下创建的所有容器都会在bridge网段

docker network inspect bridge 查看bridge网段详情

docker run -it -d --name test1 busybox
docker run -it -d --name test2 busybox

*sudo yum install -y bridge-utils这样执行 sudo brctl show*
可以清晰简单的看到连接到各网段的容器

docker run -d -it --link test2 --name test3 busybox

ping -c 4 test2



docker network create --driver bridge my-bridge

其中–driver是表示基于后面参数bridge建立的网段my-bridge
docker run -it -d --net=my-bridge --name test4 busybox 创建一个在my-bridge网段的容器

test4 和test1.2.3都不在一个网段

docker network connect bridge test4 把test4也加入bridge网段（test4会有两个ip）

进入test4网段随意ping一下bridge网段的容器





#### docker4种网络模式

1：bridge模式，--net=bridge(默认)。
这是dokcer网络的默认设置。安装完docker，系统会自动添加一个供docker使用的网桥docker0，我们创建一个新的容器时，容器通过DHCP获取一个与docker0同网段的IP地址。并默认连接到docker0网桥，以此实现容器与宿主机的网络互通。

2：host模式，--net=host。

  这个模式下创建出来的容器，将不拥有自己独立的Network Namespace，即没有独立的网络环境。它使用宿主机的ip和端口。

3：container模式，--net=container:NAME_or_ID。

这个模式就是指定一个已有的容器，共享该容器的IP和端口。除了网络方面两个容器共享，其他的如文件系统，进程等还是隔离开的。

4：none模式，--net=none。

这个模式下，dokcer不为容器进行任何网络配置。需要我们自己为容器添加网卡，配置IP。

因此，若想使用pipework配置docker容器的ip地址，必须要在none模式下才可以



docker通信工具：Pipework和Open vSwitch

pipework的工具。号称是容器网络的SDN解决方案，可以在复杂的场景下将容器连接起来。它既支持普通的LXC容器，也支持Docker容器。



1.同一主机容器之间



2.不同主机容器之间

```ruby
brctl addbr br0
[root@node1 ~]# ip link set dev br0 up
[root@node1 ~]# ip addr add 192.168.114.1/24 dev br0//这个ip相当于br0网桥的网关ip，可以随意设定。
docker run -ti -d --net=none --name=my-test2 docker.io/nginx /bin/bash
[root@node1 ~]# pipework br0 -i eth0 my-test12 192.168.114.200/24@192.168.114.1
[root@node1 ~]# pipework br0 -i eth0 my-test2 192.168.114.200/24@192.168.114.1
```

上面使用的pipework工具还，还可以使用虚拟交换机(Open vSwitch)进行docker容器间的网络通信

iproute2 正在逐步取代旧的 net-tools（ifconfig）